{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-c09c61f59676>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From E:\\Anaconda-3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From E:\\Anaconda-3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting official/mnist/dataset.py\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Anaconda-3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting official/mnist/dataset.py\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Anaconda-3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting official/mnist/dataset.py\\t10k-images-idx3-ubyte.gz\n",
      "Extracting official/mnist/dataset.py\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Anaconda-3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"official/mnist/dataset.py\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_image = mnist.train.images[100].reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x243b12d1438>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x243aec0c358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample_image, cmap=\"gist_yarg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The example image shows handwritten '7'\n",
    "## These images are already normalised as they are grayscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The min is  0.0 \n",
      "The max is  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"The min is \", round(sample_image.min()), \"\\nThe max is \", round(sample_image.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As seen above the min value is 0 and the max value is 1. Hence, the images are normalised. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Initialise weights\n",
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Initialise bias\n",
    "def init_bias(shape):\n",
    "    init_bias_values = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create a 2D convolution function\n",
    "def convTwoDim(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool(x):  ## 2x2 pool function\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution_layer(x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.sigmoid(convTwoDim(x, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connected_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32, shape=[None,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Layer 1\n",
    "conv_lay_1 = convolution_layer(x_image, shape=[5,5,1,32])\n",
    "conv_lay_1_pool = max_pool(conv_lay_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Layer 2\n",
    "conv_lay_2 = convolution_layer(conv_lay_1_pool, shape=[5,5,32,64])\n",
    "conv_lay_2_pool = max_pool(conv_lay_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_2_flat = tf.reshape(conv_lay_2_pool, [-1,7*7*64])\n",
    "full_layer_1 = tf.nn.sigmoid(fully_connected_layer(conv_2_flat, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Drop Out\n",
    "hold_prob = tf.placeholder(tf.float32)\n",
    "full_one_dropout = tf.nn.dropout(full_layer_1, keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = fully_connected_layer(full_one_dropout, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## LOSS FUNCTION\n",
    "cross_entropy =  tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true, logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On step  0\n",
      "Accuracy: \n",
      "0.1028 \n",
      "\n",
      "On step  1000\n",
      "Accuracy: \n",
      "0.9649 \n",
      "\n",
      "On step  2000\n",
      "Accuracy: \n",
      "0.9795 \n",
      "\n",
      "On step  3000\n",
      "Accuracy: \n",
      "0.9832 \n",
      "\n",
      "On step  4000\n",
      "Accuracy: \n",
      "0.9851 \n",
      "\n",
      "On step  5000\n",
      "Accuracy: \n",
      "0.9866 \n",
      "\n",
      "On step  6000\n",
      "Accuracy: \n",
      "0.9889 \n",
      "\n",
      "On step  7000\n",
      "Accuracy: \n",
      "0.9853 \n",
      "\n",
      "On step  8000\n",
      "Accuracy: \n",
      "0.9862 \n",
      "\n",
      "On step  9000\n",
      "Accuracy: \n",
      "0.9864 \n",
      "\n",
      "On step  10000\n",
      "Accuracy: \n",
      "0.9891 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps = 10001\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        batch_x, batch_y = mnist.train.next_batch(50)\n",
    "        sess.run(train, feed_dict={x:batch_x, y_true:batch_y, hold_prob:0.8})\n",
    "        \n",
    "        if i%1000 == 0:\n",
    "            print(\"On step \", i)\n",
    "            print(\"Accuracy: \")\n",
    "            matches = tf.equal(tf.argmax(y_pred,1), tf.argmax(y_true,1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "            print(sess.run(accuracy, feed_dict={x:mnist.test.images, y_true:mnist.test.labels, hold_prob:1.0}), \"\\n\")\n",
    " \n",
    "\n",
    "    ## Save the model checkpoint\n",
    "    saver.save(sess, 'models/cnn_trainedModel-1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
